{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CELL 1: Imports for whole notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "\n",
    "# Suppress warnings \n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Models, metrics, preprocessing, classifiers and stats \n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cell 2: Function to aggregate numerical data correspoding grouped by 'group_var'\n",
    "# Use: Add new columns to training set from bureau, and bureau_balance.csv\n",
    "def agg_numeric(df, group_var, df_name):\n",
    "    # Drop columns that aren't being grouped\n",
    "    for col in df:\n",
    "        if col != group_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "            \n",
    "    group_ids = df[group_var]\n",
    "    numeric_df = df.select_dtypes('number')\n",
    "    numeric_df[group_var] = group_ids\n",
    "\n",
    "    # Group id and aggregate mean, max, min, count and sum\n",
    "    agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n",
    "\n",
    "    # Create new column names\n",
    "    columns = [group_var]\n",
    "\n",
    "    # Add new column names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        if var != group_var:\n",
    "            for stat in agg.columns.levels[1][:-1]:\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "\n",
    "    agg.columns = columns\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CELL 3: Count d  counts for categorial variable in groupvar\n",
    "# Used on bureau and bureau_balance.csv\n",
    "def count_categorical(df, group_var, df_name):\n",
    "    \n",
    "    categorical = pd.get_dummies(df.select_dtypes('object'))\n",
    "\n",
    "    # Put id on col\n",
    "    categorical[group_var] = df[group_var]\n",
    "\n",
    "    # Groupby, calculate the sum and mean\n",
    "    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    for var in categorical.columns.levels[0]:\n",
    "        for stat in ['count', 'count_norm']:\n",
    "            # New column names\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    categorical.columns = column_names\n",
    "    \n",
    "    return categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cell 4: Calculates counts of missing values\n",
    "def missing_values_table(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Calculate percent\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # table of missing values and percents\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        #Sort descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "                \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cell 5: load files\n",
    "fs = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "with fs.open('ds-2019-test-buck/application_train.csv') as f:\n",
    "    train = pd.read_csv(f)\n",
    "    \n",
    "with fs.open('ds-2019-test-buck/bureau.csv') as f:\n",
    "    bureau = pd.read_csv(f)\n",
    "    \n",
    "with fs.open('ds-2019-test-buck/bureau_balance.csv') as f:\n",
    "    bureau_balance = pd.read_csv(f)\n",
    "    \n",
    "with fs.open('ds-2019-test-buck/POS_CASH_balance.csv') as f:\n",
    "    POS_CASH_balance = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6) Run four below, get aggregations and categorical counts for bureau and bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "include and exclude must both be non-string sequences",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d9930d97d954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbureau_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbureau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SK_ID_CURR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bureau'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-16c4bfa1c6fe>\u001b[0m in \u001b[0;36mcount_categorical\u001b[0;34m(df, group_var, df_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Put id on col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mselect_dtypes\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   2283\u001b[0m         \u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minclude\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2285\u001b[0;31m             raise TypeError('include and exclude must both be non-string'\n\u001b[0m\u001b[1;32m   2286\u001b[0m                             ' sequences')\n\u001b[1;32m   2287\u001b[0m         \u001b[0mselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozenset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: include and exclude must both be non-string sequences"
     ]
    }
   ],
   "source": [
    "bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bureau_agg = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bureau_balance_agg = agg_numeric(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cell 7) Creates data frame of loans stats for each client\n",
    "bureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')\n",
    "\n",
    "# Include current SK_ID\n",
    "bureau_by_loan = bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(bureau_by_loan, on = 'SK_ID_BUREAU', how = 'left')\n",
    "\n",
    "# Aggregate for each client\n",
    "bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CELL 8)\n",
    "# Aggregate stats in POS_CASH_BALANCE for each client\n",
    "valid_IDs=train['SK_ID_CURR'].copy()\n",
    "filteredPos = POS_CASH_balance.loc[POS_CASH_balance['SK_ID_CURR'].isin(valid_IDs)].sort_values(by=['SK_ID_CURR'])\n",
    "POS_agg = agg_numeric(filteredPos, group_var = 'SK_ID_CURR', df_name = 'POS_CASH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CELL 9) merge new dataframes with train\n",
    "train = train.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "train = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "train = train.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "train = train.merge(POS_agg, on='SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CELL 10) List missing values over 90%\n",
    "missing_train = missing_values_table(train)\n",
    "missing_train_vars = list(missing_train.index[missing_train['% of Total Values'] > 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CELL 11) Read in test data, merge same bureau data\n",
    "with fs.open('ds-2019-test-buck/application_test.csv') as f:\n",
    "    test = pd.read_csv(f)\n",
    "test = test.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n",
    "test = test.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "test = test.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "test = test.merge(POS_agg, on='SK_ID_CURR', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CELL 12) \n",
    "train_labels = train['TARGET']\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "train['TARGET'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CELL 13) Missing over 90% in test\n",
    "missing_test = missing_values_table(test)\n",
    "missing_test_vars = list(missing_test.index[missing_test['% of Total Values'] > 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CELL 14) Drop columns with too much missing data\n",
    "missing_columns = list(set(missing_test_vars + missing_train_vars))\n",
    "train = train.drop(columns = missing_columns)\n",
    "test = test.drop(columns = missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CELL 15) Calculate correlations\n",
    "corrs = train.corr()\n",
    "corrs = corrs.sort_values('TARGET', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CELL 16) Get variables above threshold\n",
    "threshold = 0.8\n",
    "\n",
    "above_threshold_vars = {}\n",
    "\n",
    "# Record variables above threshold\n",
    "for col in corrs:\n",
    "    above_threshold_vars[col] = list(corrs.index[corrs[col] > threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CELL 17) Get columns to remove, too colinear\n",
    "cols_to_remove = []\n",
    "cols_seen = []\n",
    "cols_to_remove_pair = []\n",
    "\n",
    "\n",
    "for key, value in above_threshold_vars.items():\n",
    "    cols_seen.append(key)\n",
    "    for x in value:\n",
    "        if x == key:\n",
    "            next\n",
    "        else:\n",
    "            if x not in cols_seen:\n",
    "                cols_to_remove.append(x)\n",
    "                cols_to_remove_pair.append(key)\n",
    "            \n",
    "cols_to_remove = list(set(cols_to_remove))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CELL 18) Remove columns calculated above\n",
    "train_corrs_removed = train.drop(columns = cols_to_remove)\n",
    "test_corrs_removed = test.drop(columns = cols_to_remove)\n",
    "\n",
    "print('Training Corrs Removed Shape: ', train_corrs_removed.shape)\n",
    "print('Testing Corrs Removed Shape: ', test_corrs_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CELL 19) Imports needed to model, classify, and compute metrics\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CELL 20) Set up dataframes to test\n",
    "train_lgb = train.copy()\n",
    "\n",
    "# Training labels\n",
    "labels = train_lgb['TARGET']\n",
    "\n",
    "# Drops IDs and Targets\n",
    "train_lgb = train_lgb.drop(columns = ['SK_ID_CURR', 'TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CELL 21) Encode, align and covert to numpy\n",
    "train_xgb = pd.get_dummies(train_xgb)\n",
    "test_xgb = pd.get_dummies(test_xgb)\n",
    "\n",
    "train_xgb, test_xgb = train_xgb.align(test_xgb, join = 'inner', axis = 1)\n",
    "\n",
    "train_xgb = np.array(train_xgb)\n",
    "test_xgb = np.array(test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CELL 22) Create numpy zeros, lists for testing\n",
    "test_predictions = np.zeros(test_xgb.shape[0])\n",
    "\n",
    "# Empty array for out of fold validation predictions\n",
    "out_of_fold = np.zeros(train_xgb.shape[0])\n",
    "\n",
    "# Lists for validation, training scores\n",
    "valid_scores = []\n",
    "train_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CELL 23) Creates models, trains and calculates respective ROCS\n",
    "%%time\n",
    "n_folds = 3\n",
    "k_fold = KFold(n_splits = n_folds, shuffle = False, random_state = 50)\n",
    "\n",
    "for train_indices, valid_indices in k_fold.split(train_xgb):\n",
    "    \n",
    "    # Training data for fold\n",
    "    train_features, train_labels = train_xgb[train_indices], labels[train_indices]\n",
    "    # Validation data for fold\n",
    "    valid_features, valid_labels = train_xgb[valid_indices], labels[valid_indices]\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.5, learning_rate = 0.15,\n",
    "            max_depth = 12, alpha = 10, n_estimators = 50)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "              eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "              early_stopping_rounds = 100, verbose = True)\n",
    "    \n",
    "    # Out of fold predictions\n",
    "    out_of_fold[valid_indices] = model.predict_proba(valid_features)[:, 1]\n",
    "    \n",
    "    # Clean memory\n",
    "    gc.enable()\n",
    "    del model, train_features, valid_features\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CELL 24) Prints final ROC\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc \n",
    "\n",
    "#Calculate AUC:\n",
    "print ('ROC AUC Score on the test dataset', roc_auc_score(labels, out_of_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CELL 25) Graphs ROC\n",
    "fpr,tpr, thresholds= roc_curve(labels, out_of_fold) \n",
    "roc_auc=auc(fpr,tpr)\n",
    "\n",
    "\n",
    "#Visual :https://www.kaggle.com/jomaxx/area-under-the-roc-curve-explained \n",
    "#fig, axs = plt.subplots(1, 2, figsize = (16,8))\n",
    "\n",
    "#Plot ROC \n",
    "plt.plot(fpr, tpr, lw=1, label='(AUC = %0.2f)' % (roc_auc))\n",
    "\n",
    "plt.title('XGBoost Classifier Receiver Operating Characteristic ')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
