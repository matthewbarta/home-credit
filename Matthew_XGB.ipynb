{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import seaborn as sns    #NOTE: Will have to install seaborn later\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agg_numeric(df, group_var, df_name):\n",
    "    \"\"\"Aggregates the numeric values in a dataframe. This can\n",
    "    be used to create features for each instance of the grouping variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        df (dataframe): \n",
    "            the dataframe to calculate the statistics on\n",
    "        group_var (string): \n",
    "            the variable by which to group df\n",
    "        df_name (string): \n",
    "            the variable used to rename the columns\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        agg (dataframe): \n",
    "            a dataframe with the statistics aggregated for \n",
    "            all numeric columns. Each instance of the grouping variable will have \n",
    "            the statistics (mean, min, max, sum; currently supported) calculated. \n",
    "            The columns are also renamed to keep track of features created.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Remove id variables other than grouping variable\n",
    "    for col in df:\n",
    "        if col != group_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "            \n",
    "    group_ids = df[group_var]\n",
    "    numeric_df = df.select_dtypes('number')\n",
    "    numeric_df[group_var] = group_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = [group_var]\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        # Skip the grouping variable\n",
    "        if var != group_var:\n",
    "            # Iterate through the stat names\n",
    "            for stat in agg.columns.levels[1][:-1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "\n",
    "    agg.columns = columns\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_categorical(df, group_var, df_name):\n",
    "    \"\"\"Computes counts and normalized counts for each observation\n",
    "    of `group_var` of each unique category in every categorical variable\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe \n",
    "        The dataframe to calculate the value counts for.\n",
    "        \n",
    "    group_var : string\n",
    "        The variable by which to group the dataframe. For each unique\n",
    "        value of this variable, the final dataframe will have one row\n",
    "        \n",
    "    df_name : string\n",
    "        Variable added to the front of column names to keep track of columns\n",
    "\n",
    "    \n",
    "    Return\n",
    "    --------\n",
    "    categorical : dataframe\n",
    "        A dataframe with counts and normalized counts of each unique category in every categorical variable\n",
    "        with one row for every unique value of the `group_var`.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the categorical columns\n",
    "    categorical = pd.get_dummies(df.select_dtypes('object'))\n",
    "\n",
    "    # Make sure to put the identifying id on the column\n",
    "    categorical[group_var] = df[group_var]\n",
    "\n",
    "    # Groupby the group var and calculate the sum and mean\n",
    "    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    # Iterate through the columns in level 0\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        # Iterate through the stats in level 1\n",
    "        for stat in ['count', 'count_norm']:\n",
    "            # Make a new column name\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    categorical.columns = column_names\n",
    "    \n",
    "    return categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column# Funct \n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "                \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "with fs.open('home-credit-mb/application_train.csv') as f:\n",
    "    train = pd.read_csv(f)\n",
    "    \n",
    "with fs.open('home-credit-mb/bureau.csv') as f:\n",
    "    bureau = pd.read_csv(f)\n",
    "    \n",
    "with fs.open('home-credit-mb/bureau_balance.csv') as f:\n",
    "    bureau_balance = pd.read_csv(f)\n",
    "    \n",
    "with fs.open('home-credit-mb/POS_CASH_balance.csv') as f:\n",
    "    POS_CASH_balance = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bureau_CREDIT_ACTIVE_Active_count</th>\n",
       "      <th>bureau_CREDIT_ACTIVE_Active_count_norm</th>\n",
       "      <th>bureau_CREDIT_ACTIVE_Bad debt_count</th>\n",
       "      <th>bureau_CREDIT_ACTIVE_Bad debt_count_norm</th>\n",
       "      <th>bureau_CREDIT_ACTIVE_Closed_count</th>\n",
       "      <th>bureau_CREDIT_ACTIVE_Closed_count_norm</th>\n",
       "      <th>bureau_CREDIT_ACTIVE_Sold_count</th>\n",
       "      <th>bureau_CREDIT_ACTIVE_Sold_count_norm</th>\n",
       "      <th>bureau_CREDIT_CURRENCY_currency 1_count</th>\n",
       "      <th>bureau_CREDIT_CURRENCY_currency 1_count_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>bureau_CREDIT_TYPE_Microloan_count</th>\n",
       "      <th>bureau_CREDIT_TYPE_Microloan_count_norm</th>\n",
       "      <th>bureau_CREDIT_TYPE_Mobile operator loan_count</th>\n",
       "      <th>bureau_CREDIT_TYPE_Mobile operator loan_count_norm</th>\n",
       "      <th>bureau_CREDIT_TYPE_Mortgage_count</th>\n",
       "      <th>bureau_CREDIT_TYPE_Mortgage_count_norm</th>\n",
       "      <th>bureau_CREDIT_TYPE_Real estate loan_count</th>\n",
       "      <th>bureau_CREDIT_TYPE_Real estate loan_count_norm</th>\n",
       "      <th>bureau_CREDIT_TYPE_Unknown type of loan_count</th>\n",
       "      <th>bureau_CREDIT_TYPE_Unknown type of loan_count_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>3</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            bureau_CREDIT_ACTIVE_Active_count  \\\n",
       "SK_ID_CURR                                      \n",
       "100001                                      3   \n",
       "100002                                      2   \n",
       "100003                                      1   \n",
       "100004                                      0   \n",
       "100005                                      2   \n",
       "\n",
       "            bureau_CREDIT_ACTIVE_Active_count_norm  \\\n",
       "SK_ID_CURR                                           \n",
       "100001                                    0.428571   \n",
       "100002                                    0.250000   \n",
       "100003                                    0.250000   \n",
       "100004                                    0.000000   \n",
       "100005                                    0.666667   \n",
       "\n",
       "            bureau_CREDIT_ACTIVE_Bad debt_count  \\\n",
       "SK_ID_CURR                                        \n",
       "100001                                        0   \n",
       "100002                                        0   \n",
       "100003                                        0   \n",
       "100004                                        0   \n",
       "100005                                        0   \n",
       "\n",
       "            bureau_CREDIT_ACTIVE_Bad debt_count_norm  \\\n",
       "SK_ID_CURR                                             \n",
       "100001                                           0.0   \n",
       "100002                                           0.0   \n",
       "100003                                           0.0   \n",
       "100004                                           0.0   \n",
       "100005                                           0.0   \n",
       "\n",
       "            bureau_CREDIT_ACTIVE_Closed_count  \\\n",
       "SK_ID_CURR                                      \n",
       "100001                                      4   \n",
       "100002                                      6   \n",
       "100003                                      3   \n",
       "100004                                      2   \n",
       "100005                                      1   \n",
       "\n",
       "            bureau_CREDIT_ACTIVE_Closed_count_norm  \\\n",
       "SK_ID_CURR                                           \n",
       "100001                                    0.571429   \n",
       "100002                                    0.750000   \n",
       "100003                                    0.750000   \n",
       "100004                                    1.000000   \n",
       "100005                                    0.333333   \n",
       "\n",
       "            bureau_CREDIT_ACTIVE_Sold_count  \\\n",
       "SK_ID_CURR                                    \n",
       "100001                                    0   \n",
       "100002                                    0   \n",
       "100003                                    0   \n",
       "100004                                    0   \n",
       "100005                                    0   \n",
       "\n",
       "            bureau_CREDIT_ACTIVE_Sold_count_norm  \\\n",
       "SK_ID_CURR                                         \n",
       "100001                                       0.0   \n",
       "100002                                       0.0   \n",
       "100003                                       0.0   \n",
       "100004                                       0.0   \n",
       "100005                                       0.0   \n",
       "\n",
       "            bureau_CREDIT_CURRENCY_currency 1_count  \\\n",
       "SK_ID_CURR                                            \n",
       "100001                                            7   \n",
       "100002                                            8   \n",
       "100003                                            4   \n",
       "100004                                            2   \n",
       "100005                                            3   \n",
       "\n",
       "            bureau_CREDIT_CURRENCY_currency 1_count_norm  \\\n",
       "SK_ID_CURR                                                 \n",
       "100001                                               1.0   \n",
       "100002                                               1.0   \n",
       "100003                                               1.0   \n",
       "100004                                               1.0   \n",
       "100005                                               1.0   \n",
       "\n",
       "                                   ...                          \\\n",
       "SK_ID_CURR                         ...                           \n",
       "100001                             ...                           \n",
       "100002                             ...                           \n",
       "100003                             ...                           \n",
       "100004                             ...                           \n",
       "100005                             ...                           \n",
       "\n",
       "            bureau_CREDIT_TYPE_Microloan_count  \\\n",
       "SK_ID_CURR                                       \n",
       "100001                                       0   \n",
       "100002                                       0   \n",
       "100003                                       0   \n",
       "100004                                       0   \n",
       "100005                                       0   \n",
       "\n",
       "            bureau_CREDIT_TYPE_Microloan_count_norm  \\\n",
       "SK_ID_CURR                                            \n",
       "100001                                          0.0   \n",
       "100002                                          0.0   \n",
       "100003                                          0.0   \n",
       "100004                                          0.0   \n",
       "100005                                          0.0   \n",
       "\n",
       "            bureau_CREDIT_TYPE_Mobile operator loan_count  \\\n",
       "SK_ID_CURR                                                  \n",
       "100001                                                  0   \n",
       "100002                                                  0   \n",
       "100003                                                  0   \n",
       "100004                                                  0   \n",
       "100005                                                  0   \n",
       "\n",
       "            bureau_CREDIT_TYPE_Mobile operator loan_count_norm  \\\n",
       "SK_ID_CURR                                                       \n",
       "100001                                                    0.0    \n",
       "100002                                                    0.0    \n",
       "100003                                                    0.0    \n",
       "100004                                                    0.0    \n",
       "100005                                                    0.0    \n",
       "\n",
       "            bureau_CREDIT_TYPE_Mortgage_count  \\\n",
       "SK_ID_CURR                                      \n",
       "100001                                      0   \n",
       "100002                                      0   \n",
       "100003                                      0   \n",
       "100004                                      0   \n",
       "100005                                      0   \n",
       "\n",
       "            bureau_CREDIT_TYPE_Mortgage_count_norm  \\\n",
       "SK_ID_CURR                                           \n",
       "100001                                         0.0   \n",
       "100002                                         0.0   \n",
       "100003                                         0.0   \n",
       "100004                                         0.0   \n",
       "100005                                         0.0   \n",
       "\n",
       "            bureau_CREDIT_TYPE_Real estate loan_count  \\\n",
       "SK_ID_CURR                                              \n",
       "100001                                              0   \n",
       "100002                                              0   \n",
       "100003                                              0   \n",
       "100004                                              0   \n",
       "100005                                              0   \n",
       "\n",
       "            bureau_CREDIT_TYPE_Real estate loan_count_norm  \\\n",
       "SK_ID_CURR                                                   \n",
       "100001                                                 0.0   \n",
       "100002                                                 0.0   \n",
       "100003                                                 0.0   \n",
       "100004                                                 0.0   \n",
       "100005                                                 0.0   \n",
       "\n",
       "            bureau_CREDIT_TYPE_Unknown type of loan_count  \\\n",
       "SK_ID_CURR                                                  \n",
       "100001                                                  0   \n",
       "100002                                                  0   \n",
       "100003                                                  0   \n",
       "100004                                                  0   \n",
       "100005                                                  0   \n",
       "\n",
       "            bureau_CREDIT_TYPE_Unknown type of loan_count_norm  \n",
       "SK_ID_CURR                                                      \n",
       "100001                                                    0.0   \n",
       "100002                                                    0.0   \n",
       "100003                                                    0.0   \n",
       "100004                                                    0.0   \n",
       "100005                                                    0.0   \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bureau_agg = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bureau_balance_agg = agg_numeric(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframe grouped by the loan\n",
    "bureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')\n",
    "\n",
    "# Merge to include the SK_ID_CURR\n",
    "bureau_by_loan = bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(bureau_by_loan, on = 'SK_ID_BUREAU', how = 'left')\n",
    "\n",
    "# Aggregate the stats for each client\n",
    "bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregate stats for each client in POS_CASH\n",
    "valid_IDs=train['SK_ID_CURR'].copy()\n",
    "filteredPos = POS_CASH_balance.loc[POS_CASH_balance['SK_ID_CURR'].isin(valid_IDs)].sort_values(by=['SK_ID_CURR'])\n",
    "POS_agg = agg_numeric(filteredPos, group_var = 'SK_ID_CURR', df_name = 'POS_CASH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Number of Features:  122\n"
     ]
    }
   ],
   "source": [
    "original_features = list(train.columns)\n",
    "print('Original Number of Features: ', len(original_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge with the value counts of bureau\n",
    "train = train.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the stats of bureau\n",
    "train = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the monthly information grouped by client\n",
    "train = train.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with POS_cash\n",
    "train = train.merge(POS_agg, on='SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_train = missing_values_table(train)\n",
    "missing_train_vars = list(missing_train.index[missing_train['% of Total Values'] > 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the test dataframe\n",
    "with fs.open('home-credit-mb/application_test.csv') as f:\n",
    "    test = pd.read_csv(f)\n",
    "# Merge with the value counts of bureau\n",
    "test = test.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the stats of bureau\n",
    "test = test.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the value counts of bureau balance\n",
    "test = test.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with POS_cash\n",
    "test = test.merge(POS_agg, on='SK_ID_CURR', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train['TARGET']\n",
    "\n",
    "# Align the dataframes, this will remove the 'TARGET' column\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "\n",
    "train['TARGET'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_test = missing_values_table(test)\n",
    "missing_test_vars = list(missing_test.index[missing_test['% of Total Values'] > 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_columns = list(set(missing_test_vars + missing_train_vars))\n",
    "train = train.drop(columns = missing_columns)\n",
    "test = test.drop(columns = missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes a while to run\n",
    "corrs = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrs = corrs.sort_values('TARGET', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the threshold\n",
    "threshold = 0.8\n",
    "\n",
    "# Empty dictionary to hold correlated variables\n",
    "above_threshold_vars = {}\n",
    "\n",
    "# For each column, record the variables that are above the threshold\n",
    "for col in corrs:\n",
    "    above_threshold_vars[col] = list(corrs.index[corrs[col] > threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns to remove:  129\n"
     ]
    }
   ],
   "source": [
    "# Track columns to remove and columns already examined\n",
    "cols_to_remove = []\n",
    "cols_seen = []\n",
    "cols_to_remove_pair = []\n",
    "\n",
    "# Iterate through columns and correlated columns\n",
    "for key, value in above_threshold_vars.items():\n",
    "    # Keep track of columns already examined\n",
    "    cols_seen.append(key)\n",
    "    for x in value:\n",
    "        if x == key:\n",
    "            next\n",
    "        else:\n",
    "            # Only want to remove one in a pair\n",
    "            if x not in cols_seen:\n",
    "                cols_to_remove.append(x)\n",
    "                cols_to_remove_pair.append(key)\n",
    "            \n",
    "cols_to_remove = list(set(cols_to_remove))\n",
    "print('Number of columns to remove: ', len(cols_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Corrs Removed Shape:  (307511, 204)\n",
      "Testing Corrs Removed Shape:  (48744, 203)\n"
     ]
    }
   ],
   "source": [
    "train_corrs_removed = train.drop(columns = cols_to_remove)\n",
    "test_corrs_removed = test.drop(columns = cols_to_remove)\n",
    "\n",
    "print('Training Corrs Removed Shape: ', train_corrs_removed.shape)\n",
    "print('Testing Corrs Removed Shape: ', test_corrs_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(features, test_features):\n",
    "    \n",
    "    \"\"\"Train and test a light gradient boosting model using\n",
    "    cross validation. \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        features (pd.DataFrame): \n",
    "            dataframe of training features to use \n",
    "            for training a model. Must include the TARGET column.\n",
    "        test_features (pd.DataFrame): \n",
    "            dataframe of testing features to use\n",
    "            for making predictions with the model. \n",
    "            n_folds (int, default = 5): number of folds to use for cross validation\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        submission (pd.DataFrame): \n",
    "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n",
    "            predicted by the model.\n",
    "        feature_importances (pd.DataFrame): \n",
    "            dataframe with the feature importances from the model.\n",
    "        valid_metrics (pd.DataFrame): \n",
    "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n",
    "        \n",
    "    \"\"\"\n",
    "    n_folds = 5\n",
    "    \n",
    "    # Extract the ids\n",
    "    train_ids = features['SK_ID_CURR']\n",
    "    test_ids = test_features['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = features['TARGET']\n",
    "    \n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "    \n",
    "    # One Hot Encoding\n",
    "    features = pd.get_dummies(features)\n",
    "    test_features = pd.get_dummies(test_features)\n",
    "        \n",
    "    # Align the dataframes by the columns\n",
    "    features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "        \n",
    "    # No categorical indices to record\n",
    "    cat_indices = 'auto'\n",
    "        \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = False, random_state = 50)\n",
    "    \n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        \n",
    "        # Create the model\n",
    "        model = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.5, learning_rate = 0.15,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  early_stopping_rounds = 100, verbose = True)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration\n",
    "        \n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features)[:, 1]\n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score\n",
    "        \n",
    "        train_score = model.best_score\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "        \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    return submission, feature_importances, metrics, out_of_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_feature_importances(df):\n",
    "    \"\"\"\n",
    "    Plot importances returned by a model. This can work with any measure of\n",
    "    feature importance provided that higher importance is better. \n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): feature importances. Must have the features in a column\n",
    "        called `features` and the importances in a column called `importance\n",
    "        \n",
    "    Returns:\n",
    "        shows a plot of the 15 most importance features\n",
    "        \n",
    "        df (dataframe): feature importances sorted by importance (highest to lowest) \n",
    "        with a column for normalized importance\n",
    "        \"\"\"\n",
    "    \n",
    "    # Sort features according to importance\n",
    "    df = df.sort_values('importance', ascending = False).reset_index()\n",
    "    \n",
    "    # Normalize the feature importances to add up to one\n",
    "    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n",
    "\n",
    "    # Make a horizontal bar chart of feature importances\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    # Need to reverse the index to plot most important on top\n",
    "    ax.barh(list(reversed(list(df.index[:15]))), \n",
    "            df['importance_normalized'].head(15), \n",
    "            align = 'center', edgecolor = 'k')\n",
    "    \n",
    "    # Set the yticks and labels\n",
    "    ax.set_yticks(list(reversed(list(df.index[:15]))))\n",
    "    ax.set_yticklabels(df['feature'].head(15))\n",
    "    \n",
    "    # Plot labeling\n",
    "    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual = train['TARGET'];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (307511, 452)\n",
      "Testing Data Shape:  (48744, 452)\n",
      "[0]\tvalidation_0-auc:0.68747\tvalidation_1-auc:0.71337\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-auc:0.70449\tvalidation_1-auc:0.73721\n",
      "[2]\tvalidation_0-auc:0.71182\tvalidation_1-auc:0.75972\n",
      "[3]\tvalidation_0-auc:0.72867\tvalidation_1-auc:0.78343\n",
      "[4]\tvalidation_0-auc:0.72734\tvalidation_1-auc:0.78952\n",
      "[5]\tvalidation_0-auc:0.73323\tvalidation_1-auc:0.80046\n",
      "[6]\tvalidation_0-auc:0.73402\tvalidation_1-auc:0.80445\n",
      "[7]\tvalidation_0-auc:0.73723\tvalidation_1-auc:0.81103\n",
      "[8]\tvalidation_0-auc:0.73642\tvalidation_1-auc:0.81783\n",
      "[9]\tvalidation_0-auc:0.73789\tvalidation_1-auc:0.82157\n",
      "[10]\tvalidation_0-auc:0.73853\tvalidation_1-auc:0.82618\n",
      "[11]\tvalidation_0-auc:0.73909\tvalidation_1-auc:0.83054\n",
      "[12]\tvalidation_0-auc:0.74204\tvalidation_1-auc:0.83704\n",
      "[13]\tvalidation_0-auc:0.74364\tvalidation_1-auc:0.84160\n",
      "[14]\tvalidation_0-auc:0.74406\tvalidation_1-auc:0.84601\n",
      "[15]\tvalidation_0-auc:0.74460\tvalidation_1-auc:0.84911\n",
      "[16]\tvalidation_0-auc:0.74448\tvalidation_1-auc:0.85283\n",
      "[17]\tvalidation_0-auc:0.74531\tvalidation_1-auc:0.85605\n",
      "[18]\tvalidation_0-auc:0.74623\tvalidation_1-auc:0.85986\n",
      "[19]\tvalidation_0-auc:0.74737\tvalidation_1-auc:0.86465\n",
      "[20]\tvalidation_0-auc:0.74771\tvalidation_1-auc:0.86996\n",
      "[21]\tvalidation_0-auc:0.74879\tvalidation_1-auc:0.87388\n",
      "[22]\tvalidation_0-auc:0.75036\tvalidation_1-auc:0.87833\n",
      "[23]\tvalidation_0-auc:0.75142\tvalidation_1-auc:0.88211\n",
      "[24]\tvalidation_0-auc:0.75190\tvalidation_1-auc:0.88556\n",
      "[25]\tvalidation_0-auc:0.75152\tvalidation_1-auc:0.88902\n",
      "[26]\tvalidation_0-auc:0.75150\tvalidation_1-auc:0.89121\n",
      "[27]\tvalidation_0-auc:0.75148\tvalidation_1-auc:0.89478\n",
      "[28]\tvalidation_0-auc:0.75140\tvalidation_1-auc:0.89767\n",
      "[29]\tvalidation_0-auc:0.75173\tvalidation_1-auc:0.90103\n",
      "[30]\tvalidation_0-auc:0.75191\tvalidation_1-auc:0.90478\n",
      "[31]\tvalidation_0-auc:0.75216\tvalidation_1-auc:0.90670\n",
      "[32]\tvalidation_0-auc:0.75297\tvalidation_1-auc:0.90986\n",
      "[33]\tvalidation_0-auc:0.75307\tvalidation_1-auc:0.91196\n",
      "[34]\tvalidation_0-auc:0.75315\tvalidation_1-auc:0.91431\n",
      "[35]\tvalidation_0-auc:0.75371\tvalidation_1-auc:0.91663\n",
      "[36]\tvalidation_0-auc:0.75396\tvalidation_1-auc:0.91810\n",
      "[37]\tvalidation_0-auc:0.75411\tvalidation_1-auc:0.92056\n",
      "[38]\tvalidation_0-auc:0.75445\tvalidation_1-auc:0.92293\n",
      "[39]\tvalidation_0-auc:0.75480\tvalidation_1-auc:0.92507\n",
      "[40]\tvalidation_0-auc:0.75537\tvalidation_1-auc:0.92644\n",
      "[41]\tvalidation_0-auc:0.75536\tvalidation_1-auc:0.92828\n",
      "[42]\tvalidation_0-auc:0.75577\tvalidation_1-auc:0.92888\n",
      "[43]\tvalidation_0-auc:0.75606\tvalidation_1-auc:0.93008\n",
      "[44]\tvalidation_0-auc:0.75638\tvalidation_1-auc:0.93096\n",
      "[45]\tvalidation_0-auc:0.75665\tvalidation_1-auc:0.93219\n",
      "[46]\tvalidation_0-auc:0.75702\tvalidation_1-auc:0.93341\n",
      "[47]\tvalidation_0-auc:0.75689\tvalidation_1-auc:0.93429\n",
      "[48]\tvalidation_0-auc:0.75680\tvalidation_1-auc:0.93548\n",
      "[49]\tvalidation_0-auc:0.75693\tvalidation_1-auc:0.93625\n",
      "[0]\tvalidation_0-auc:0.68539\tvalidation_1-auc:0.71149\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-auc:0.70384\tvalidation_1-auc:0.74103\n",
      "[2]\tvalidation_0-auc:0.70660\tvalidation_1-auc:0.75912\n",
      "[3]\tvalidation_0-auc:0.72294\tvalidation_1-auc:0.78018\n",
      "[4]\tvalidation_0-auc:0.72384\tvalidation_1-auc:0.78677\n",
      "[5]\tvalidation_0-auc:0.72986\tvalidation_1-auc:0.79828\n",
      "[6]\tvalidation_0-auc:0.73065\tvalidation_1-auc:0.80235\n",
      "[7]\tvalidation_0-auc:0.73434\tvalidation_1-auc:0.80974\n",
      "[8]\tvalidation_0-auc:0.73345\tvalidation_1-auc:0.81579\n",
      "[9]\tvalidation_0-auc:0.73532\tvalidation_1-auc:0.82038\n",
      "[10]\tvalidation_0-auc:0.73541\tvalidation_1-auc:0.82510\n",
      "[11]\tvalidation_0-auc:0.73560\tvalidation_1-auc:0.82883\n",
      "[12]\tvalidation_0-auc:0.73845\tvalidation_1-auc:0.83405\n",
      "[13]\tvalidation_0-auc:0.74000\tvalidation_1-auc:0.83861\n",
      "[14]\tvalidation_0-auc:0.74095\tvalidation_1-auc:0.84266\n",
      "[15]\tvalidation_0-auc:0.74132\tvalidation_1-auc:0.84763\n",
      "[16]\tvalidation_0-auc:0.74240\tvalidation_1-auc:0.85104\n",
      "[17]\tvalidation_0-auc:0.74309\tvalidation_1-auc:0.85550\n",
      "[18]\tvalidation_0-auc:0.74352\tvalidation_1-auc:0.86017\n",
      "[19]\tvalidation_0-auc:0.74466\tvalidation_1-auc:0.86452\n",
      "[20]\tvalidation_0-auc:0.74542\tvalidation_1-auc:0.86966\n",
      "[21]\tvalidation_0-auc:0.74635\tvalidation_1-auc:0.87329\n",
      "[22]\tvalidation_0-auc:0.74785\tvalidation_1-auc:0.87778\n",
      "[23]\tvalidation_0-auc:0.74831\tvalidation_1-auc:0.88191\n",
      "[24]\tvalidation_0-auc:0.74801\tvalidation_1-auc:0.88590\n",
      "[25]\tvalidation_0-auc:0.74857\tvalidation_1-auc:0.88917\n",
      "[26]\tvalidation_0-auc:0.74843\tvalidation_1-auc:0.89045\n",
      "[27]\tvalidation_0-auc:0.74857\tvalidation_1-auc:0.89417\n",
      "[28]\tvalidation_0-auc:0.74873\tvalidation_1-auc:0.89698\n",
      "[29]\tvalidation_0-auc:0.74911\tvalidation_1-auc:0.89951\n",
      "[30]\tvalidation_0-auc:0.74984\tvalidation_1-auc:0.90207\n",
      "[31]\tvalidation_0-auc:0.75038\tvalidation_1-auc:0.90500\n",
      "[32]\tvalidation_0-auc:0.75099\tvalidation_1-auc:0.90797\n",
      "[33]\tvalidation_0-auc:0.75135\tvalidation_1-auc:0.91047\n",
      "[34]\tvalidation_0-auc:0.75131\tvalidation_1-auc:0.91258\n",
      "[35]\tvalidation_0-auc:0.75206\tvalidation_1-auc:0.91492\n",
      "[36]\tvalidation_0-auc:0.75214\tvalidation_1-auc:0.91664\n",
      "[37]\tvalidation_0-auc:0.75242\tvalidation_1-auc:0.91939\n",
      "[38]\tvalidation_0-auc:0.75275\tvalidation_1-auc:0.92069\n",
      "[39]\tvalidation_0-auc:0.75343\tvalidation_1-auc:0.92282\n",
      "[40]\tvalidation_0-auc:0.75383\tvalidation_1-auc:0.92364\n",
      "[41]\tvalidation_0-auc:0.75419\tvalidation_1-auc:0.92527\n",
      "[42]\tvalidation_0-auc:0.75450\tvalidation_1-auc:0.92734\n",
      "[43]\tvalidation_0-auc:0.75463\tvalidation_1-auc:0.92847\n",
      "[44]\tvalidation_0-auc:0.75475\tvalidation_1-auc:0.92986\n",
      "[45]\tvalidation_0-auc:0.75477\tvalidation_1-auc:0.93107\n",
      "[46]\tvalidation_0-auc:0.75494\tvalidation_1-auc:0.93258\n",
      "[47]\tvalidation_0-auc:0.75480\tvalidation_1-auc:0.93317\n",
      "[48]\tvalidation_0-auc:0.75496\tvalidation_1-auc:0.93420\n",
      "[49]\tvalidation_0-auc:0.75499\tvalidation_1-auc:0.93502\n",
      "[0]\tvalidation_0-auc:0.68155\tvalidation_1-auc:0.71413\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-auc:0.69820\tvalidation_1-auc:0.74160\n",
      "[2]\tvalidation_0-auc:0.70660\tvalidation_1-auc:0.76340\n",
      "[3]\tvalidation_0-auc:0.72117\tvalidation_1-auc:0.78546\n",
      "[4]\tvalidation_0-auc:0.72275\tvalidation_1-auc:0.79111\n",
      "[5]\tvalidation_0-auc:0.72747\tvalidation_1-auc:0.80311\n",
      "[6]\tvalidation_0-auc:0.72903\tvalidation_1-auc:0.80754\n",
      "[7]\tvalidation_0-auc:0.73117\tvalidation_1-auc:0.81371\n",
      "[8]\tvalidation_0-auc:0.73110\tvalidation_1-auc:0.82008\n",
      "[9]\tvalidation_0-auc:0.73057\tvalidation_1-auc:0.82438\n",
      "[10]\tvalidation_0-auc:0.73085\tvalidation_1-auc:0.82926\n",
      "[11]\tvalidation_0-auc:0.73064\tvalidation_1-auc:0.83264\n",
      "[12]\tvalidation_0-auc:0.73374\tvalidation_1-auc:0.83867\n",
      "[13]\tvalidation_0-auc:0.73549\tvalidation_1-auc:0.84255\n",
      "[14]\tvalidation_0-auc:0.73649\tvalidation_1-auc:0.84656\n",
      "[15]\tvalidation_0-auc:0.73740\tvalidation_1-auc:0.85047\n",
      "[16]\tvalidation_0-auc:0.73818\tvalidation_1-auc:0.85312\n",
      "[17]\tvalidation_0-auc:0.73833\tvalidation_1-auc:0.85629\n",
      "[18]\tvalidation_0-auc:0.73904\tvalidation_1-auc:0.86028\n",
      "[19]\tvalidation_0-auc:0.74052\tvalidation_1-auc:0.86615\n",
      "[20]\tvalidation_0-auc:0.74135\tvalidation_1-auc:0.87104\n",
      "[21]\tvalidation_0-auc:0.74212\tvalidation_1-auc:0.87446\n",
      "[22]\tvalidation_0-auc:0.74328\tvalidation_1-auc:0.87887\n",
      "[23]\tvalidation_0-auc:0.74371\tvalidation_1-auc:0.88255\n",
      "[24]\tvalidation_0-auc:0.74363\tvalidation_1-auc:0.88559\n",
      "[25]\tvalidation_0-auc:0.74379\tvalidation_1-auc:0.88915\n",
      "[26]\tvalidation_0-auc:0.74418\tvalidation_1-auc:0.89131\n",
      "[27]\tvalidation_0-auc:0.74389\tvalidation_1-auc:0.89424\n",
      "[28]\tvalidation_0-auc:0.74427\tvalidation_1-auc:0.89832\n",
      "[29]\tvalidation_0-auc:0.74470\tvalidation_1-auc:0.90147\n",
      "[30]\tvalidation_0-auc:0.74546\tvalidation_1-auc:0.90507\n",
      "[31]\tvalidation_0-auc:0.74571\tvalidation_1-auc:0.90785\n",
      "[32]\tvalidation_0-auc:0.74694\tvalidation_1-auc:0.91126\n",
      "[33]\tvalidation_0-auc:0.74726\tvalidation_1-auc:0.91295\n",
      "[34]\tvalidation_0-auc:0.74720\tvalidation_1-auc:0.91480\n",
      "[35]\tvalidation_0-auc:0.74747\tvalidation_1-auc:0.91696\n",
      "[36]\tvalidation_0-auc:0.74750\tvalidation_1-auc:0.91850\n",
      "[37]\tvalidation_0-auc:0.74735\tvalidation_1-auc:0.92072\n",
      "[38]\tvalidation_0-auc:0.74734\tvalidation_1-auc:0.92266\n",
      "[39]\tvalidation_0-auc:0.74749\tvalidation_1-auc:0.92439\n",
      "[40]\tvalidation_0-auc:0.74830\tvalidation_1-auc:0.92600\n",
      "[41]\tvalidation_0-auc:0.74871\tvalidation_1-auc:0.92803\n",
      "[42]\tvalidation_0-auc:0.74882\tvalidation_1-auc:0.92929\n",
      "[43]\tvalidation_0-auc:0.74920\tvalidation_1-auc:0.93032\n",
      "[44]\tvalidation_0-auc:0.74947\tvalidation_1-auc:0.93131\n",
      "[45]\tvalidation_0-auc:0.74968\tvalidation_1-auc:0.93224\n",
      "[46]\tvalidation_0-auc:0.74968\tvalidation_1-auc:0.93336\n",
      "[47]\tvalidation_0-auc:0.75010\tvalidation_1-auc:0.93399\n",
      "[48]\tvalidation_0-auc:0.75013\tvalidation_1-auc:0.93524\n",
      "[49]\tvalidation_0-auc:0.75018\tvalidation_1-auc:0.93625\n",
      "[0]\tvalidation_0-auc:0.68586\tvalidation_1-auc:0.71201\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-auc:0.70522\tvalidation_1-auc:0.73922\n",
      "[2]\tvalidation_0-auc:0.70877\tvalidation_1-auc:0.76108\n",
      "[3]\tvalidation_0-auc:0.72763\tvalidation_1-auc:0.78089\n",
      "[4]\tvalidation_0-auc:0.72945\tvalidation_1-auc:0.78605\n",
      "[5]\tvalidation_0-auc:0.73623\tvalidation_1-auc:0.79891\n",
      "[6]\tvalidation_0-auc:0.73721\tvalidation_1-auc:0.80307\n",
      "[7]\tvalidation_0-auc:0.73975\tvalidation_1-auc:0.81091\n",
      "[8]\tvalidation_0-auc:0.73900\tvalidation_1-auc:0.81669\n",
      "[9]\tvalidation_0-auc:0.73989\tvalidation_1-auc:0.82081\n",
      "[10]\tvalidation_0-auc:0.73990\tvalidation_1-auc:0.82510\n",
      "[11]\tvalidation_0-auc:0.74085\tvalidation_1-auc:0.83018\n",
      "[12]\tvalidation_0-auc:0.74408\tvalidation_1-auc:0.83585\n",
      "[13]\tvalidation_0-auc:0.74582\tvalidation_1-auc:0.84035\n",
      "[14]\tvalidation_0-auc:0.74713\tvalidation_1-auc:0.84446\n",
      "[15]\tvalidation_0-auc:0.74717\tvalidation_1-auc:0.84846\n",
      "[16]\tvalidation_0-auc:0.74808\tvalidation_1-auc:0.85232\n",
      "[17]\tvalidation_0-auc:0.74815\tvalidation_1-auc:0.85628\n",
      "[18]\tvalidation_0-auc:0.74880\tvalidation_1-auc:0.86081\n",
      "[19]\tvalidation_0-auc:0.74962\tvalidation_1-auc:0.86563\n",
      "[20]\tvalidation_0-auc:0.75047\tvalidation_1-auc:0.87064\n",
      "[21]\tvalidation_0-auc:0.75085\tvalidation_1-auc:0.87520\n",
      "[22]\tvalidation_0-auc:0.75196\tvalidation_1-auc:0.87953\n",
      "[23]\tvalidation_0-auc:0.75128\tvalidation_1-auc:0.88302\n",
      "[24]\tvalidation_0-auc:0.75188\tvalidation_1-auc:0.88698\n",
      "[25]\tvalidation_0-auc:0.75189\tvalidation_1-auc:0.89014\n",
      "[26]\tvalidation_0-auc:0.75192\tvalidation_1-auc:0.89221\n",
      "[27]\tvalidation_0-auc:0.75196\tvalidation_1-auc:0.89522\n",
      "[28]\tvalidation_0-auc:0.75226\tvalidation_1-auc:0.89799\n",
      "[29]\tvalidation_0-auc:0.75245\tvalidation_1-auc:0.90024\n",
      "[30]\tvalidation_0-auc:0.75260\tvalidation_1-auc:0.90346\n",
      "[31]\tvalidation_0-auc:0.75322\tvalidation_1-auc:0.90672\n",
      "[32]\tvalidation_0-auc:0.75431\tvalidation_1-auc:0.90937\n",
      "[33]\tvalidation_0-auc:0.75454\tvalidation_1-auc:0.91156\n",
      "[34]\tvalidation_0-auc:0.75460\tvalidation_1-auc:0.91309\n",
      "[35]\tvalidation_0-auc:0.75512\tvalidation_1-auc:0.91518\n",
      "[36]\tvalidation_0-auc:0.75533\tvalidation_1-auc:0.91688\n",
      "[37]\tvalidation_0-auc:0.75550\tvalidation_1-auc:0.91907\n",
      "[38]\tvalidation_0-auc:0.75564\tvalidation_1-auc:0.92007\n",
      "[39]\tvalidation_0-auc:0.75561\tvalidation_1-auc:0.92233\n",
      "[40]\tvalidation_0-auc:0.75589\tvalidation_1-auc:0.92318\n",
      "[41]\tvalidation_0-auc:0.75606\tvalidation_1-auc:0.92527\n",
      "[42]\tvalidation_0-auc:0.75584\tvalidation_1-auc:0.92744\n",
      "[43]\tvalidation_0-auc:0.75574\tvalidation_1-auc:0.92830\n",
      "[44]\tvalidation_0-auc:0.75577\tvalidation_1-auc:0.92933\n",
      "[45]\tvalidation_0-auc:0.75617\tvalidation_1-auc:0.93020\n",
      "[46]\tvalidation_0-auc:0.75621\tvalidation_1-auc:0.93093\n",
      "[47]\tvalidation_0-auc:0.75633\tvalidation_1-auc:0.93148\n",
      "[48]\tvalidation_0-auc:0.75616\tvalidation_1-auc:0.93260\n",
      "[49]\tvalidation_0-auc:0.75619\tvalidation_1-auc:0.93375\n",
      "[0]\tvalidation_0-auc:0.68661\tvalidation_1-auc:0.71108\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-auc:0.70475\tvalidation_1-auc:0.73744\n",
      "[2]\tvalidation_0-auc:0.71048\tvalidation_1-auc:0.75996\n",
      "[3]\tvalidation_0-auc:0.72594\tvalidation_1-auc:0.78211\n",
      "[4]\tvalidation_0-auc:0.72664\tvalidation_1-auc:0.78900\n",
      "[5]\tvalidation_0-auc:0.73406\tvalidation_1-auc:0.79980\n",
      "[6]\tvalidation_0-auc:0.73452\tvalidation_1-auc:0.80366\n",
      "[7]\tvalidation_0-auc:0.73908\tvalidation_1-auc:0.80992\n",
      "[8]\tvalidation_0-auc:0.73746\tvalidation_1-auc:0.81666\n",
      "[9]\tvalidation_0-auc:0.74023\tvalidation_1-auc:0.82173\n",
      "[10]\tvalidation_0-auc:0.74013\tvalidation_1-auc:0.82565\n",
      "[11]\tvalidation_0-auc:0.74021\tvalidation_1-auc:0.82971\n",
      "[12]\tvalidation_0-auc:0.74268\tvalidation_1-auc:0.83514\n",
      "[13]\tvalidation_0-auc:0.74421\tvalidation_1-auc:0.83943\n",
      "[14]\tvalidation_0-auc:0.74499\tvalidation_1-auc:0.84309\n",
      "[15]\tvalidation_0-auc:0.74670\tvalidation_1-auc:0.84816\n",
      "[16]\tvalidation_0-auc:0.74750\tvalidation_1-auc:0.85097\n",
      "[17]\tvalidation_0-auc:0.74718\tvalidation_1-auc:0.85545\n",
      "[18]\tvalidation_0-auc:0.74820\tvalidation_1-auc:0.86035\n",
      "[19]\tvalidation_0-auc:0.74884\tvalidation_1-auc:0.86479\n",
      "[20]\tvalidation_0-auc:0.75009\tvalidation_1-auc:0.86871\n",
      "[21]\tvalidation_0-auc:0.75042\tvalidation_1-auc:0.87360\n",
      "[22]\tvalidation_0-auc:0.75139\tvalidation_1-auc:0.87791\n",
      "[23]\tvalidation_0-auc:0.75163\tvalidation_1-auc:0.88090\n",
      "[24]\tvalidation_0-auc:0.75232\tvalidation_1-auc:0.88469\n",
      "[25]\tvalidation_0-auc:0.75249\tvalidation_1-auc:0.88741\n",
      "[26]\tvalidation_0-auc:0.75251\tvalidation_1-auc:0.88951\n",
      "[27]\tvalidation_0-auc:0.75265\tvalidation_1-auc:0.89255\n",
      "[28]\tvalidation_0-auc:0.75291\tvalidation_1-auc:0.89554\n",
      "[29]\tvalidation_0-auc:0.75276\tvalidation_1-auc:0.89852\n",
      "[30]\tvalidation_0-auc:0.75341\tvalidation_1-auc:0.90216\n",
      "[31]\tvalidation_0-auc:0.75368\tvalidation_1-auc:0.90470\n",
      "[32]\tvalidation_0-auc:0.75461\tvalidation_1-auc:0.90770\n",
      "[33]\tvalidation_0-auc:0.75454\tvalidation_1-auc:0.90953\n",
      "[34]\tvalidation_0-auc:0.75451\tvalidation_1-auc:0.91189\n",
      "[35]\tvalidation_0-auc:0.75459\tvalidation_1-auc:0.91435\n",
      "[36]\tvalidation_0-auc:0.75487\tvalidation_1-auc:0.91562\n",
      "[37]\tvalidation_0-auc:0.75569\tvalidation_1-auc:0.91782\n",
      "[38]\tvalidation_0-auc:0.75584\tvalidation_1-auc:0.91952\n",
      "[39]\tvalidation_0-auc:0.75580\tvalidation_1-auc:0.92201\n",
      "[40]\tvalidation_0-auc:0.75645\tvalidation_1-auc:0.92328\n",
      "[41]\tvalidation_0-auc:0.75652\tvalidation_1-auc:0.92492\n",
      "[42]\tvalidation_0-auc:0.75667\tvalidation_1-auc:0.92710\n",
      "[43]\tvalidation_0-auc:0.75661\tvalidation_1-auc:0.92777\n",
      "[44]\tvalidation_0-auc:0.75669\tvalidation_1-auc:0.92920\n",
      "[45]\tvalidation_0-auc:0.75686\tvalidation_1-auc:0.93088\n",
      "[46]\tvalidation_0-auc:0.75707\tvalidation_1-auc:0.93213\n",
      "[47]\tvalidation_0-auc:0.75738\tvalidation_1-auc:0.93310\n",
      "[48]\tvalidation_0-auc:0.75750\tvalidation_1-auc:0.93354\n",
      "[49]\tvalidation_0-auc:0.75743\tvalidation_1-auc:0.93410\n"
     ]
    }
   ],
   "source": [
    "submission_raw, fi_raw, metrics_raw, oof_raw = model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score on the test dataset 0.7551112138563686\n"
     ]
    }
   ],
   "source": [
    "#ROC AUC Curve \n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc \n",
    "\n",
    "#Calculate AUC:\n",
    "print ('ROC AUC Score on the test dataset', roc_auc_score (actual, oof_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f04fbade4e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGHCAYAAAAHoqCrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0503273080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr,tpr, thresholds= roc_curve(actual, oof_raw) \n",
    "roc_auc=auc(fpr,tpr)\n",
    "\n",
    "\n",
    "#Visual :https://www.kaggle.com/jomaxx/area-under-the-roc-curve-explained \n",
    "#fig, axs = plt.subplots(1, 2, figsize = (16,8))\n",
    "\n",
    "#Plot ROC \n",
    "plt.plot(fpr, tpr, lw=1, label='(AUC = %0.2f)' % (roc_auc))\n",
    "\n",
    "plt.title('XGBoost Classifier Receiver Operating Characteristic ')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_sorted = plot_feature_importances(fi_raw)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
